{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv1D, Conv2D, MaxPool2D, Reshape\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "# unused for now, to be used for ROC analysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# the size of the images in the PCAM dataset\n",
    "IMAGE_SIZE = 96\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     TRAIN_PATH = os.path.join(base_dir, 'train')\n",
    "     VALID_PATH = os.path.join(base_dir, 'valid')\n",
    "\n",
    "     RESCALING_FACTOR = 1./255\n",
    "     \n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(TRAIN_PATH,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(VALID_PATH,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary',\n",
    "                                             shuffle=False)\n",
    "     \n",
    "     return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(kernel_size=(3,3), pool_size=(4,4), first_filters=32, second_filters=64):\n",
    "\n",
    "\n",
    "     # build the model\n",
    "     model = Sequential()\n",
    "\n",
    "     model.add(Conv2D(first_filters, kernel_size, activation = 'relu', padding = 'same', input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "     model.add(MaxPool2D(pool_size = pool_size)) \n",
    "\n",
    "     model.add(Conv2D(second_filters, kernel_size, activation = 'relu', padding = 'same'))\n",
    "     model.add(MaxPool2D(pool_size = pool_size))\n",
    "\n",
    "     #model.add(Flatten())\n",
    "     model.add(Conv2D(filters = 1,kernel_size=(6,6), activation = 'sigmoid'))\n",
    "     model.add(Flatten())\n",
    "     \n",
    "    \n",
    "     # compile the model\n",
    "     model.compile(SGD(lr=0.01, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# get the model\n",
    "model = get_model()\n",
    "\n",
    "# get the data generators\n",
    "train_gen, val_gen = get_pcam_generators('C:\\\\Users\\\\s165635\\\\Desktop\\\\Project Imaging (8P361)\\\\Dataset CHAMELYON16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 96, 96, 32)\n",
      "(None, 24, 24, 32)\n",
      "(None, 24, 24, 64)\n",
      "(None, 6, 6, 64)\n",
      "(None, 1, 1, 1)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 1170s 260ms/step - loss: 0.4805 - acc: 0.7727 - val_loss: 0.4579 - val_acc: 0.7826\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45791, saving model to my_first_cnn_model_weights.hdf5\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 1089s 242ms/step - loss: 0.3967 - acc: 0.8259 - val_loss: 0.3572 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45791 to 0.35716, saving model to my_first_cnn_model_weights.hdf5\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 1250s 278ms/step - loss: 0.3702 - acc: 0.8393 - val_loss: 0.3486 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35716 to 0.34857, saving model to my_first_cnn_model_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# save the model and weights\n",
    "model_name = 'my_first_cnn_model'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "model_json = model.to_json() # serialize model to JSON\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json) \n",
    "\n",
    "\n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "# train the model\n",
    "train_steps = train_gen.n//train_gen.batch_size\n",
    "val_steps = val_gen.n//val_gen.batch_size\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=3,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
